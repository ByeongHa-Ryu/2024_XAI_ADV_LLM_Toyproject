{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install numpy==1.23.1\n",
        "# !pip install mxnet\n",
        "# !pip install gluonnlp pandas tqdm\n",
        "# !pip install sentencepiece\n",
        "# !pip install transformers\n",
        "# !pip install torch\n",
        "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qG3eATL1hjX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqbezJpASoXf",
        "outputId": "8a660e81-ccb9-479e-8af6-135aa4213896"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_pickle('data/dataset_small.pkl')\n",
        "data # 796867"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "label_dicts = {} \n",
        "\n",
        "encoder.fit(data['상권업종중분류명'])\n",
        "label_dict = dict(zip(encoder.transform(encoder.classes_), encoder.classes_))\n",
        "data['상권업종중분류명'] = encoder.transform(data['상권업종중분류명'])\n",
        "label_dicts['상권업종중분류명'] = label_dict \n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BERTClassifier2(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes = 75, # mid\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier2, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(text):\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        return_token_type_ids=True,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    token_type_ids = encoding['token_type_ids']\n",
        "    valid_length = torch.tensor([torch.sum(attention_mask[0])], dtype=torch.long)\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, valid_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model, input_ids, attention_mask, token_type_ids, valid_length):\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    token_type_ids = token_type_ids.to(device)\n",
        "    valid_length = valid_length.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, valid_length, token_type_ids)\n",
        "        probabilities = torch.softmax(outputs, dim=1) \n",
        "        predicted_class = torch.argmax(probabilities, dim=1)\n",
        "        return predicted_class"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mid_dicts = label_dicts['상권업종중분류명']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inf = pd.read_excel('data/infdata.xlsx')\n",
        "inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79NpI6jTR5C6"
      },
      "outputs": [],
      "source": [
        "model2 = torch.load('model/model2.pth')\n",
        "model2.eval()\n",
        "\n",
        "# 인퍼런스 수행\n",
        "results2 = []\n",
        "for text in inf['의뢰인/수취인']:\n",
        "    input_ids, attention_mask, token_type_ids, valid_length = prepare_data(text)\n",
        "    prediction2 = predict(model2, input_ids, attention_mask, token_type_ids, valid_length) \n",
        "    results2.append(prediction2.item())\n",
        "\n",
        "# 결과를 데이터프레임에 추가\n",
        "inf['mid'] = results2\n",
        "\n",
        "# 컬럼값 문자로 변경\n",
        "inf['mid'] = inf['mid'].map(mid_dicts)\n",
        "\n",
        "inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inf.to_excel('result/data/infdata_result.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
